{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from time import perf_counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_ = Path('imagedata')\n",
    "filepaths = list(dir_.glob(r'**/*.jpg'))\n",
    "def proc_img(filepath):\n",
    "    \"\"\"\n",
    "   \t\t이미지데이터의 경로와 label데이터로 데이터프레임 만들기 \n",
    "    \"\"\"\n",
    "\n",
    "    labels = [str(filepath[i]).split(\"/\")[-2] \\\n",
    "              for i in range(len(filepath))]\n",
    "\n",
    "    filepath = pd.Series(filepath, name='Filepath').astype(str)\n",
    "    labels = pd.Series(labels, name='Label')\n",
    "\n",
    "    # 경로와 라벨 concatenate\n",
    "    df = pd.concat([filepath, labels], axis=1)\n",
    "\n",
    "    # index 재설정\n",
    "    df = df.sample(frac=1,random_state=0).reset_index(drop = True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = proc_img(filepaths)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_label = len(df.Label.unique())\n",
    "print(f'Number of pictures: {df.shape[0]}\\n')\n",
    "print(f'Number of different labels: {num_label}\\n')\n",
    "print(f'Labels: {df.Label.unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 확인\n",
    "fig, axes = plt.subplots(nrows=4, ncols=10, figsize=(15, 7),\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(plt.imread(df.Filepath[i]))\n",
    "    ax.set_title(df.Label[i], fontsize = 12)\n",
    "plt.tight_layout(pad=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = df['Label'].value_counts()\n",
    "plt.figure(figsize=(9,5))\n",
    "sns.barplot(y = vc.index, x = vc, palette = \"rocket\", orient = 'h')\n",
    "plt.title(\"Number of pictures of each category\", fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training/test split\n",
    "# train_df,test_df = train_test_split(df.sample(frac=0.2), test_size=0.1,random_state=0) #모델링 시간이 오래걸리면 사용\n",
    "train_df,test_df = train_test_split(df, test_size=0.1,random_state=0)\n",
    "train_df.shape,test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "\n",
    "\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "#                                    validation_split=0.2)\n",
    "\n",
    "# train_gen = train_datagen.flow_from_directory('/content/drive/MyDrive/Colab Notebooks/Data_analysis_Project/03_딥러닝_이미지분류/imagedata/data/natural_images',\n",
    "#                                                  target_size = (150, 150),\n",
    "#                                                  batch_size = 32,\n",
    "#                                                  class_mode = 'categorical',subset='training')\n",
    "# val_gen  = train_datagen.flow_from_directory('/content/drive/MyDrive/Colab Notebooks/Data_analysis_Project/03_딥러닝_이미지분류/imagedata/data/natural_images',\n",
    "#                                                  target_size = (150, 150),\n",
    "#                                                  batch_size = 32,\n",
    "#                                                  class_mode = 'categorical',subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialising the CNN\n",
    "# cnn = tf.keras.models.Sequential()\n",
    "\n",
    "# # Step 1 - Convolution\n",
    "# cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[150, 150, 3]))\n",
    "\n",
    "# # Step 2 - Pooling\n",
    "# cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "# # Adding convolutional layer\n",
    "# cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "# cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "# # Step 3 - Flattening\n",
    "# cnn.add(tf.keras.layers.Flatten())\n",
    "\n",
    "# # Step 4 - Full Connection\n",
    "# cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "\n",
    "# # Step 5 - Output Layer\n",
    "# cnn.add(tf.keras.layers.Dense(units=18, activation='softmax'))\n",
    "\n",
    "# # Compiling the CNN\n",
    "# cnn.compile(optimizer = 'adam', \n",
    "#             loss = 'categorical_crossentropy', \n",
    "#             metrics = ['accuracy'])\n",
    "# cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gen():\n",
    "    # 생성기 및 데이터 증강으로 이미지 로드\n",
    "    train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n",
    "        validation_split=0.1\n",
    "    )\n",
    "\n",
    "    test_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "    )\n",
    "\n",
    "    train_images = train_generator.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        x_col='Filepath', # 파일위치 열이름\n",
    "        y_col='Label', # 클래스 열이름\n",
    "        target_size=(224, 224), # 이미지 사이즈\n",
    "        color_mode='rgb', # 이미지 채널수\n",
    "        class_mode='categorical', # Y값(Label값)\n",
    "        batch_size=32,\n",
    "        shuffle=True, # 데이터를 섞을지 여부\n",
    "        seed=0,\n",
    "        subset='training', # train 인지 val인지 설정\n",
    "        rotation_range=30, # 회전제한 각도 30도\n",
    "        zoom_range=0.15, # 확대 축소 15%\n",
    "        width_shift_range=0.2, # 좌우이동 20%\n",
    "        height_shift_range=0.2, # 상하이동 20%\n",
    "        shear_range=0.15, # 반시계방햐의 각도\n",
    "        horizontal_flip=True, # 좌우 반전 True\n",
    "        fill_mode=\"nearest\"\n",
    "        # 이미지 변경시 보완 방법 (constant, nearest, reflect, wrap) 4개 존재\n",
    "    )\n",
    "\n",
    "    val_images = train_generator.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        x_col='Filepath',\n",
    "        y_col='Label',\n",
    "        target_size=(224, 224),\n",
    "        color_mode='rgb',\n",
    "        class_mode='categorical',\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "        seed=0,\n",
    "        subset='validation',\n",
    "        rotation_range=30,\n",
    "        zoom_range=0.15,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.15,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode=\"nearest\"\n",
    "    )\n",
    "\n",
    "    test_images = test_generator.flow_from_dataframe(\n",
    "        dataframe=test_df,\n",
    "        x_col='Filepath',\n",
    "        y_col='Label',\n",
    "        target_size=(224, 224),\n",
    "        color_mode='rgb',\n",
    "        class_mode='categorical',\n",
    "        batch_size=32,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    return train_generator,test_generator,train_images,val_images,test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"DenseNet121\": {\"model\":tf.keras.applications.DenseNet121, \"perf\":0},\n",
    "    \"MobileNetV2\": {\"model\":tf.keras.applications.MobileNetV2, \"perf\":0},\n",
    "    \"DenseNet201\": {\"model\":tf.keras.applications.DenseNet201, \"perf\":0},\n",
    "    \"EfficientNetB0\": {\"model\":tf.keras.applications.EfficientNetB0, \"perf\":0},\n",
    "    \"EfficientNetB1\": {\"model\":tf.keras.applications.EfficientNetB1, \"perf\":0},\n",
    "    \"InceptionV3\": {\"model\":tf.keras.applications.InceptionV3, \"perf\":0},\n",
    "    \"MobileNetV2\": {\"model\":tf.keras.applications.MobileNetV2, \"perf\":0},\n",
    "    \"MobileNetV3Large\": {\"model\":tf.keras.applications.MobileNetV3Large, \"perf\":0},\n",
    "    \"ResNet152V2\": {\"model\":tf.keras.applications.ResNet152V2, \"perf\":0},\n",
    "    \"ResNet50\": {\"model\":tf.keras.applications.ResNet50, \"perf\":0},\n",
    "    \"ResNet50V2\": {\"model\":tf.keras.applications.ResNet50V2, \"perf\":0},\n",
    "    \"VGG19\": {\"model\":tf.keras.applications.VGG19, \"perf\":0},\n",
    "    \"VGG16\": {\"model\":tf.keras.applications.VGG16, \"perf\":0},\n",
    "    \"Xception\": {\"model\":tf.keras.applications.Xception, \"perf\":0}\n",
    "}\n",
    "# Create the generators\n",
    "#train_generator,test_generator,train_images,val_images,test_images=create_gen()\n",
    "#print('\\n')\n",
    "\n",
    "def get_model(model):\n",
    "# Load the pretained model\n",
    "    kwargs =    {'input_shape':(224, 224, 3),\n",
    "                'include_top':False,\n",
    "                'weights':'imagenet',\n",
    "                'pooling':'avg'}\n",
    "    \n",
    "    pretrained_model = model(**kwargs)\n",
    "    pretrained_model.trainable = False # 레이어를 동결 시켜서 훈련중 손실을 최소화 한다.\n",
    "    \n",
    "    inputs = pretrained_model.input\n",
    "\n",
    "    x = tf.keras.layers.Dense(128, activation='relu')(pretrained_model.output)\n",
    "    x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(num_label, activation='softmax')(x)\n",
    "    # 라벨 개수가 8개이기 때문에 Dencs도 8로 설정\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# # Train모델 학습\n",
    "# for name, model in models.items():\n",
    "    \n",
    "#     # 전이 학습 모델 가져오기\n",
    "#     m = get_model(model['model'])\n",
    "#     models[name]['model'] = m\n",
    "    \n",
    "#     start = perf_counter()\n",
    "    \n",
    "#     # 모델 학습\n",
    "#     history = m.fit(train_images,validation_data=val_images,epochs=1,verbose=0)\n",
    "    \n",
    "#     # 학습시간과 val_accuracy 저장\n",
    "#     duration = perf_counter() - start\n",
    "#     duration = round(duration,2)\n",
    "#     models[name]['perf'] = duration\n",
    "#     print(f\"{name:20} trained in {duration} sec\")\n",
    "    \n",
    "#     val_acc = history.history['val_accuracy']\n",
    "#     models[name]['val_acc'] = [round(v,4) for v in val_acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test데이터로 모델 성능 예측\n",
    "# for name, model in models.items():\n",
    "    \n",
    "#     # Predict the label of the test_images\n",
    "#     pred = models[name]['model'].predict(test_images)\n",
    "#     pred = np.argmax(pred,axis=1)\n",
    "\n",
    "#     # Map the label\n",
    "#     labels = (train_images.class_indices)\n",
    "#     labels = dict((v,k) for k,v in labels.items())\n",
    "#     pred = [labels[k] for k in pred]\n",
    "\n",
    "#     y_test = list(test_df.Label)\n",
    "#     acc = accuracy_score(y_test,pred)\n",
    "#     models[name]['acc'] = round(acc,4)\n",
    "#     print(f'**{name} has a {acc * 100:.2f}% accuracy on the test set**')\n",
    "   \n",
    "# # Create a DataFrame with the results\n",
    "# models_result = []\n",
    "\n",
    "# for name, v in models.items():\n",
    "#     models_result.append([ name, models[name]['val_acc'][-1], \n",
    "#                           models[name]['acc'],\n",
    "#                           models[name]['perf']])\n",
    "    \n",
    "# df_results = pd.DataFrame(models_result, \n",
    "#                           columns = ['model','val_accuracy','accuracy','Training time (sec)'])\n",
    "# df_results.sort_values(by='accuracy', ascending=False, inplace=True)\n",
    "# df_results.reset_index(inplace=True,drop=True)\n",
    "# df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize = (15,5))\n",
    "# sns.barplot(x = 'model', y = 'accuracy', data = df_results)\n",
    "# plt.title('Accuracy on the test set (after 1 epoch))', fontsize = 15)\n",
    "# plt.ylim(0,1)\n",
    "# plt.xticks(rotation=90)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize = (15,5))\n",
    "# sns.barplot(x = 'model', y = 'Training time (sec)', data = df_results)\n",
    "# plt.title('Training time for each model in sec', fontsize = 15)\n",
    "# # plt.ylim(0,20)\n",
    "# plt.xticks(rotation=90)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#효율 좋은 모델 확인\n",
    "train_df,test_df = train_test_split(df, test_size=0.1, random_state=0)\n",
    "train_generator,test_generator,train_images,val_images,test_images=create_gen()\n",
    "\n",
    "model = get_model(tf.keras.applications.DenseNet201)\n",
    "history = model.fit(train_images,validation_data=val_images,epochs=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history)[['accuracy','val_accuracy']].plot()\n",
    "plt.title(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history)[['loss','val_loss']].plot()\n",
    "plt.title(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the label of the test_images\n",
    "pred = model.predict(test_images)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "\n",
    "# Map the label\n",
    "labels = (train_images.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "pred = [labels[k] for k in pred]\n",
    "    \n",
    "y_test = list(test_df.Label)\n",
    "acc = accuracy_score(y_test,pred)\n",
    "print(f'Accuracy on the test set: {acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('saved_model/')\n",
    "\n",
    "with open('saved_model/class_indices.pkl', 'wb') as f:\n",
    "    pickle.dump(train_images.class_indices, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
    "\n",
    "def printmd(string):\n",
    "    # Print with Markdowns    \n",
    "    display(Markdown(string))\n",
    "    \n",
    "class_dictionary = {'airplane': 0,\n",
    "                    'car': 1,\n",
    "                    'cat': 2,\n",
    "                    'dog': 3,\n",
    "                    'flower': 4,\n",
    "                    'fruit': 5,\n",
    "                    'motorbike': 6,\n",
    "                    'person': 7}\n",
    "\n",
    "IMAGE_SIZE    = (224, 224)\n",
    "number_1 = int(input(\"번호를 입력하세요 : \")) # 10, 50, 100\n",
    "test_image = image.load_img(test_df.iloc[number_1, 0]\n",
    "                            ,target_size =IMAGE_SIZE )\n",
    "test_image = image.img_to_array(test_image)\n",
    "plt.imshow(test_image/255.);\n",
    "\n",
    "test_image = test_image.reshape((1, test_image.shape[0], test_image.shape[1], test_image.shape[2]))\n",
    "test_image = preprocess_input(test_image)\n",
    "prediction = model.predict(test_image)\n",
    "\n",
    "df = pd.DataFrame({'pred':prediction[0]})\n",
    "df = df.sort_values(by='pred', ascending=False, na_position='first')\n",
    "printmd(f\"## 예측률 : {(df.iloc[0]['pred'])* 100:.2f}%\")\n",
    "\n",
    "for x in class_dictionary:\n",
    "  if class_dictionary[x] == (df[df == df.iloc[0]].index[0]):\n",
    "    printmd(f\"### Class prediction = {x}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display picture of the dataset with their labels\n",
    "fig, axes = plt.subplots(nrows=4, ncols=6, figsize=(20, 12),\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(plt.imread(test_df.Filepath.iloc[i]))\n",
    "    ax.set_title(f\"True: {test_df.Label.iloc[i].split('_')[0]}\\nPredicted: {pred[i].split('_')[0]}\", fontsize = 15)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yeardream",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
